{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Lab 14: Your First AI Agent\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/depalmar/ai_for_the_win/blob/main/notebooks/lab14_first_ai_agent.ipynb)\n\nBuild a simple ReAct agent from scratch to understand how AI agents work.\n\n## Learning Objectives\n- Understand the ReAct (Reason + Act) pattern\n- Build a simple agent loop from scratch\n- Implement tool calling for security tasks\n- Debug agent behavior and handle edge cases\n\n## What is an AI Agent?\n\nAn AI agent is an LLM that can:\n1. **Reason** about a task\n2. **Act** by calling tools\n3. **Observe** the results\n4. **Repeat** until the task is done\n\n**Next:** Lab 36 (Threat Intel Agent)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Install dependencies (Colab only)\n",
    "#@markdown Run this cell to install required packages in Colab\n",
    "\n",
    "%pip install -q anthropic openai google-generativeai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title LLM Setup (Provider-Agnostic)\n",
    "#@markdown Set your API key in Colab Secrets (üîë icon in sidebar)\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from typing import Dict, List, Any, Callable\n",
    "\n",
    "# Try to load from Colab secrets\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    for key in [\"ANTHROPIC_API_KEY\", \"OPENAI_API_KEY\", \"GOOGLE_API_KEY\"]:\n",
    "        try:\n",
    "            os.environ[key] = userdata.get(key)\n",
    "        except:\n",
    "            pass\n",
    "except:\n",
    "    pass  # Not in Colab, use environment variables\n",
    "\n",
    "def setup_llm():\n",
    "    \"\"\"Detect and configure LLM provider.\"\"\"\n",
    "    if os.environ.get(\"ANTHROPIC_API_KEY\"):\n",
    "        return \"anthropic\", \"claude-sonnet-4.5\"\n",
    "    elif os.environ.get(\"OPENAI_API_KEY\"):\n",
    "        return \"openai\", \"gpt-5\"\n",
    "    elif os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "        return \"google\", \"gemini-3-flash\"\n",
    "    raise ValueError(\"No API key found. Add one to Colab Secrets.\")\n",
    "\n",
    "def query_llm(prompt: str, system: str = \"You are a security analyst.\") -> str:\n",
    "    \"\"\"Query the configured LLM.\"\"\"\n",
    "    provider, model = setup_llm()\n",
    "    \n",
    "    if provider == \"anthropic\":\n",
    "        from anthropic import Anthropic\n",
    "        client = Anthropic()\n",
    "        response = client.messages.create(\n",
    "            model=model, max_tokens=2048, system=system,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        return response.content[0].text\n",
    "    elif provider == \"openai\":\n",
    "        from openai import OpenAI\n",
    "        client = OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=model, max_tokens=2048,\n",
    "            messages=[{\"role\": \"system\", \"content\": system}, {\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    elif provider == \"google\":\n",
    "        import google.generativeai as genai\n",
    "        genai.configure(api_key=os.environ.get(\"GOOGLE_API_KEY\"))\n",
    "        model_instance = genai.GenerativeModel(model)\n",
    "        response = model_instance.generate_content(f\"{system}\\n\\n{prompt}\")\n",
    "        return response.text\n",
    "\n",
    "provider, model = setup_llm()\n",
    "print(f\"‚úÖ Using {provider} ({model})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Define Our Tools\n",
    "\n",
    "Tools are functions the agent can call. Let's create some security-focused tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock threat intelligence database\n",
    "THREAT_INTEL_DB = {\n",
    "    \"192.168.1.100\": {\"malicious\": False, \"category\": \"internal\"},\n",
    "    \"45.33.32.156\": {\"malicious\": True, \"category\": \"c2_server\", \"actor\": \"APT28\"},\n",
    "    \"evil.com\": {\"malicious\": True, \"category\": \"phishing\"},\n",
    "    \"google.com\": {\"malicious\": False, \"category\": \"legitimate\"},\n",
    "}\n",
    "\n",
    "def lookup_ip(ip: str) -> Dict:\n",
    "    \"\"\"Look up an IP address in threat intelligence.\"\"\"\n",
    "    if ip in THREAT_INTEL_DB:\n",
    "        return THREAT_INTEL_DB[ip]\n",
    "    return {\"malicious\": False, \"category\": \"unknown\", \"note\": \"Not in database\"}\n",
    "\n",
    "def lookup_domain(domain: str) -> Dict:\n",
    "    \"\"\"Look up a domain in threat intelligence.\"\"\"\n",
    "    if domain in THREAT_INTEL_DB:\n",
    "        return THREAT_INTEL_DB[domain]\n",
    "    return {\"malicious\": False, \"category\": \"unknown\", \"note\": \"Not in database\"}\n",
    "\n",
    "def check_hash(file_hash: str) -> Dict:\n",
    "    \"\"\"Check if a file hash is known malware.\"\"\"\n",
    "    # Mock implementation\n",
    "    known_malware = {\n",
    "        \"abc123\": {\"malicious\": True, \"family\": \"Emotet\"},\n",
    "        \"def456\": {\"malicious\": True, \"family\": \"Cobalt Strike\"},\n",
    "    }\n",
    "    return known_malware.get(file_hash, {\"malicious\": False, \"note\": \"Unknown hash\"})\n",
    "\n",
    "# Tool registry\n",
    "TOOLS = {\n",
    "    \"lookup_ip\": lookup_ip,\n",
    "    \"lookup_domain\": lookup_domain,\n",
    "    \"check_hash\": check_hash,\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Tools defined:\", list(TOOLS.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Build the Agent Loop\n",
    "\n",
    "The agent loop is the core of any AI agent. It:\n",
    "1. Asks the LLM what to do\n",
    "2. Parses the response for tool calls\n",
    "3. Executes the tool\n",
    "4. Feeds the result back to the LLM\n",
    "5. Repeats until done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENT_SYSTEM_PROMPT = \"\"\"\n",
    "You are a security analyst agent. You can use tools to investigate security questions.\n",
    "\n",
    "Available tools:\n",
    "- lookup_ip(ip): Look up an IP address in threat intelligence\n",
    "- lookup_domain(domain): Look up a domain in threat intelligence  \n",
    "- check_hash(hash): Check if a file hash is known malware\n",
    "\n",
    "To use a tool, respond with:\n",
    "THOUGHT: [your reasoning]\n",
    "ACTION: tool_name(\"argument\")\n",
    "\n",
    "After receiving tool results, continue reasoning.\n",
    "\n",
    "When you have enough information, respond with:\n",
    "THOUGHT: [final reasoning]\n",
    "FINAL ANSWER: [your conclusion]\n",
    "\"\"\"\n",
    "\n",
    "def parse_agent_response(response: str) -> tuple:\n",
    "    \"\"\"Parse agent response to extract action or final answer.\"\"\"\n",
    "    # Check for final answer\n",
    "    if \"FINAL ANSWER:\" in response:\n",
    "        answer = response.split(\"FINAL ANSWER:\")[-1].strip()\n",
    "        return (\"final\", answer)\n",
    "    \n",
    "    # Check for action\n",
    "    action_match = re.search(r'ACTION:\\s*(\\w+)\\(\"([^\"]+)\"\\)', response)\n",
    "    if action_match:\n",
    "        tool_name = action_match.group(1)\n",
    "        argument = action_match.group(2)\n",
    "        return (\"action\", tool_name, argument)\n",
    "    \n",
    "    return (\"error\", \"Could not parse response\")\n",
    "\n",
    "def run_agent(query: str, max_steps: int = 5) -> str:\n",
    "    \"\"\"Run the agent loop.\"\"\"\n",
    "    conversation = f\"User Query: {query}\\n\\n\"\n",
    "    \n",
    "    for step in range(max_steps):\n",
    "        print(f\"\\n--- Step {step + 1} ---\")\n",
    "        \n",
    "        # Get LLM response\n",
    "        response = query_llm(conversation, AGENT_SYSTEM_PROMPT)\n",
    "        print(f\"Agent: {response[:500]}...\" if len(response) > 500 else f\"Agent: {response}\")\n",
    "        \n",
    "        # Parse response\n",
    "        parsed = parse_agent_response(response)\n",
    "        \n",
    "        if parsed[0] == \"final\":\n",
    "            print(f\"\\n‚úÖ Final Answer: {parsed[1]}\")\n",
    "            return parsed[1]\n",
    "        \n",
    "        elif parsed[0] == \"action\":\n",
    "            tool_name, argument = parsed[1], parsed[2]\n",
    "            print(f\"\\nüîß Calling tool: {tool_name}({argument})\")\n",
    "            \n",
    "            if tool_name in TOOLS:\n",
    "                result = TOOLS[tool_name](argument)\n",
    "                print(f\"üìä Result: {result}\")\n",
    "                conversation += f\"{response}\\n\\nOBSERVATION: {json.dumps(result)}\\n\\n\"\n",
    "            else:\n",
    "                conversation += f\"{response}\\n\\nOBSERVATION: Error - Unknown tool '{tool_name}'\\n\\n\"\n",
    "        \n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Parse error: {parsed[1]}\")\n",
    "            conversation += f\"{response}\\n\\nOBSERVATION: Please use the correct format.\\n\\n\"\n",
    "    \n",
    "    return \"Max steps reached without conclusion.\"\n",
    "\n",
    "print(\"‚úÖ Agent loop defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Test the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Simple IP lookup\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 1: Is 45.33.32.156 malicious?\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "result = run_agent(\"Is the IP address 45.33.32.156 malicious?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Multi-step investigation\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 2: Multi-indicator investigation\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "result = run_agent(\n",
    "    \"I found a suspicious connection to evil.com from IP 192.168.1.100. \"\n",
    "    \"Can you investigate both indicators?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### Exercise 1: Add a new tool\n",
    "Add a `get_whois(domain)` tool that returns mock WHOIS data.\n",
    "\n",
    "### Exercise 2: Improve error handling\n",
    "What happens if the LLM doesn't follow the format? Add better error recovery.\n",
    "\n",
    "### Exercise 3: Add memory\n",
    "Modify the agent to remember previous investigations in the same session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- **Lab 16**: Build a more sophisticated threat intelligence agent with LangChain\n",
    "- **Lab 18**: Add RAG to give your agent access to documentation\n",
    "- **Lab 10**: Build a full IR Copilot with state management"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
