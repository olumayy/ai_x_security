{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Lab 04: ML Concepts Primer\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/depalmar/ai_for_the_win/blob/main/notebooks/lab04_ml_concepts.ipynb)\n\nUnderstand machine learning theory before coding. No coding required - just concepts!\n\n## Learning Objectives\n- Supervised vs unsupervised learning\n- Features and labels\n- Training, validation, and testing\n- Evaluation metrics\n\n**Next:** Lab 31 (Prompt Engineering) or Lab 21 (Hello World ML)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is Machine Learning?\n",
    "\n",
    "Machine learning is teaching computers to learn patterns from data instead of explicit programming.\n",
    "\n",
    "**Traditional Programming:**\n",
    "```\n",
    "Rules + Data â†’ Program â†’ Output\n",
    "```\n",
    "\n",
    "**Machine Learning:**\n",
    "```\n",
    "Data + Expected Output â†’ ML Algorithm â†’ Model (learned rules)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Supervised Learning\n\nLearning from labeled examples - **like studying with an answer key!**\n\n### ğŸ“š The Metaphor: Learning with a Teacher\n\nThink of supervised learning like a student studying for an exam with a study guide that has **questions AND answers**:\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  SUPERVISED LEARNING = Learning with an Answer Key              â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                                 â”‚\nâ”‚   Student sees:                        Teacher provides:        â”‚\nâ”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚\nâ”‚   â”‚ Email text   â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚ \"phishing\"   â”‚         â”‚\nâ”‚   â”‚ with 5 URLs  â”‚                    â”‚              â”‚         â”‚\nâ”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚\nâ”‚                                                                 â”‚\nâ”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚\nâ”‚   â”‚ Email from   â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚ \"legitimate\" â”‚         â”‚\nâ”‚   â”‚ known sender â”‚                    â”‚              â”‚         â”‚\nâ”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚\nâ”‚                                                                 â”‚\nâ”‚   After seeing 1000s of examples, the student learns:          â”‚\nâ”‚   \"Lots of URLs + urgency = probably phishing!\"                â”‚\nâ”‚                                                                 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n### ğŸ¯ Real-World Analogy\n\n| Scenario | Input (Features) | Output (Label) |\n|----------|------------------|----------------|\n| Medical diagnosis | Symptoms, test results | Disease name |\n| Spam filter | Email text, sender | Spam / Not spam |\n| Malware detection | File behavior, imports | Malware / Benign |\n| Fraud detection | Transaction details | Fraudulent / Legitimate |\n\n**The key insight**: Someone had to manually label the training data first. In security, this often means analysts spending hours classifying threats!"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of supervised learning\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(42)\n",
    "legitimate = np.random.randn(50, 2) + [2, 2]\n",
    "phishing = np.random.randn(50, 2) + [5, 5]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(legitimate[:, 0], legitimate[:, 1], c=\"green\", label=\"Legitimate\", alpha=0.7)\n",
    "plt.scatter(phishing[:, 0], phishing[:, 1], c=\"red\", label=\"Phishing\", alpha=0.7)\n",
    "plt.xlabel(\"Feature 1 (e.g., URL count)\")\n",
    "plt.ylabel(\"Feature 2 (e.g., urgency words)\")\n",
    "plt.title(\"Supervised Learning: Labeled Data\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. Unsupervised Learning\n\nFinding patterns without labels - **like sorting a messy closet!**\n\n### ğŸ“š The Metaphor: Organizing Without Instructions\n\nImagine you're handed a box of 1000 random objects and told: \"Sort these into groups.\" No one tells you what the groups should be - you just find natural groupings yourself:\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  UNSUPERVISED LEARNING = Organizing Without Instructions        â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                                 â”‚\nâ”‚   Before (raw data):           After (discovered clusters):    â”‚\nâ”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚\nâ”‚   â”‚ ğŸ¾âš½ğŸ€âš¾ğŸ±ğŸ“±     â”‚          â”‚ Sports:         â”‚             â”‚\nâ”‚   â”‚ ğŸ’»ğŸ–±ï¸ğŸ“ºğŸˆğŸ¿ğŸ®     â”‚    â†’     â”‚ ğŸ¾âš½ğŸ€âš¾ğŸˆğŸ¿     â”‚             â”‚\nâ”‚   â”‚ ğŸ–¨ï¸ğŸ“»ğŸ“±ğŸ¿ğŸ–¥ï¸      â”‚          â”‚                 â”‚             â”‚\nâ”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚ Electronics:    â”‚             â”‚\nâ”‚                                â”‚ ğŸ“±ğŸ’»ğŸ–±ï¸ğŸ“ºğŸ®ğŸ–¨ï¸ğŸ“»ğŸ–¥ï¸ â”‚             â”‚\nâ”‚                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚\nâ”‚                                                                 â”‚\nâ”‚   The algorithm discovered \"sports\" vs \"electronics\"           â”‚\nâ”‚   without anyone telling it those categories exist!            â”‚\nâ”‚                                                                 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n### ğŸ” Supervised vs Unsupervised: Side by Side\n\n| Aspect | Supervised | Unsupervised |\n|--------|------------|--------------|\n| **Analogy** | Learning with answer key | Exploring without instructions |\n| **Data needed** | Features + Labels | Features only |\n| **Goal** | Predict known categories | Discover hidden patterns |\n| **Example** | \"Is this malware?\" | \"What groups exist in my data?\" |\n| **Use when** | You know what to look for | You don't know what's there |\n\n### ğŸ¯ Security Use Cases for Unsupervised Learning\n\n1. **Threat Hunting**: Group similar network connections â†’ find anomalies\n2. **Malware Families**: Cluster samples â†’ discover new variants\n3. **User Behavior**: Group activity patterns â†’ detect compromised accounts\n4. **Log Analysis**: Find unusual log patterns you didn't know to look for"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Generate unlabeled data\n",
    "np.random.seed(42)\n",
    "cluster1 = np.random.randn(30, 2) + [0, 0]\n",
    "cluster2 = np.random.randn(30, 2) + [4, 4]\n",
    "cluster3 = np.random.randn(30, 2) + [0, 4]\n",
    "data = np.vstack([cluster1, cluster2, cluster3])\n",
    "\n",
    "# Apply clustering\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "labels = kmeans.fit_predict(data)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(data[:, 0], data[:, 1], c=labels, cmap=\"viridis\", alpha=0.7)\n",
    "plt.scatter(\n",
    "    kmeans.cluster_centers_[:, 0],\n",
    "    kmeans.cluster_centers_[:, 1],\n",
    "    c=\"red\",\n",
    "    marker=\"X\",\n",
    "    s=200,\n",
    "    label=\"Centers\",\n",
    ")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.title(\"Unsupervised Learning: Clustering\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Features and Labels\n",
    "\n",
    "**Features (X):** Input variables the model learns from\n",
    "- Email: word count, URL count, sender domain\n",
    "- Malware: file size, imports, entropy\n",
    "- Network: bytes sent, packet count, duration\n",
    "\n",
    "**Labels (y):** What we want to predict\n",
    "- Classification: phishing/legitimate, malware/benign\n",
    "- Regression: threat score (0-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example feature table\n",
    "data = {\n",
    "    \"email_length\": [150, 500, 200, 1000],\n",
    "    \"url_count\": [5, 1, 8, 0],\n",
    "    \"urgent_words\": [3, 0, 5, 1],\n",
    "    \"label\": [\"phishing\", \"legitimate\", \"phishing\", \"legitimate\"],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Features (X) and Labels (y):\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train/Test Split\n",
    "\n",
    "**Why split data?**\n",
    "- Training set: Model learns from this\n",
    "- Test set: Evaluate on unseen data\n",
    "- Prevents overfitting (memorizing instead of learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate sample data\n",
    "X = np.random.randn(100, 2)\n",
    "y = (X[:, 0] + X[:, 1] > 0).astype(int)\n",
    "\n",
    "# Split: 80% train, 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### âš ï¸ The Danger of Overfitting: Memorizing vs Learning\n\n**Overfitting** is when a model memorizes the training data instead of learning general patterns. It's like a student who memorizes test answers without understanding the concepts.\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                    OVERFITTING: The Core Problem                            â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                                             â”‚\nâ”‚   GOOD MODEL (Generalization)         BAD MODEL (Overfitting)               â”‚\nâ”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€           â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€              â”‚\nâ”‚                                                                             â”‚\nâ”‚   Training: 95% accuracy              Training: 99.9% accuracy              â”‚\nâ”‚   Test:     93% accuracy              Test:     60% accuracy                â”‚\nâ”‚                                                                             â”‚\nâ”‚   âœ… Similar performance =            âŒ Huge gap = PROBLEM!                â”‚\nâ”‚      learned real patterns                memorized training data           â”‚\nâ”‚                                                                             â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                                             â”‚\nâ”‚   ğŸ“š ANALOGY: The Cheating Student                                          â”‚\nâ”‚                                                                             â”‚\nâ”‚   Imagine two students studying for a phishing detection test:              â”‚\nâ”‚                                                                             â”‚\nâ”‚   Student A (Good model):                                                   â”‚\nâ”‚   \"I notice phishing emails often have urgency, suspicious links,          â”‚\nâ”‚    and grammar mistakes. I'll look for those patterns.\"                    â”‚\nâ”‚   â†’ Does well on practice tests AND the real exam âœ…                       â”‚\nâ”‚                                                                             â”‚\nâ”‚   Student B (Overfitting):                                                  â”‚\nâ”‚   \"I'll memorize every exact practice question word-for-word.\"             â”‚\nâ”‚   â†’ Perfect on practice tests, fails the real exam âŒ                      â”‚\nâ”‚                                                                             â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n### ğŸ¯ Why This Matters for Security\n\nIn security ML, overfitting is **dangerous**:\n\n| Scenario | What happens with overfitting |\n|----------|------------------------------|\n| Malware detection | Model memorizes training malware signatures, misses new variants |\n| Phishing detection | Model memorizes specific phishing emails, misses new campaigns |\n| Intrusion detection | Model learns training attack patterns, misses novel attacks |\n\n**The solution**: Always test on data the model has never seen (the test set)!",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Visual demonstration of overfitting vs good fit\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.pipeline import make_pipeline\n\nnp.random.seed(42)\n\n# Generate some noisy data (imagine: file_size vs threat_score)\nX_demo = np.linspace(0, 10, 15).reshape(-1, 1)\ny_demo = 2 * np.sin(X_demo).ravel() + np.random.normal(0, 0.5, 15)  # True pattern + noise\n\n# Create test points\nX_test_demo = np.linspace(0, 10, 100).reshape(-1, 1)\n\nfig, axes = plt.subplots(1, 3, figsize=(14, 4))\n\n# Model 1: Underfitting (too simple - straight line)\nmodel_simple = LinearRegression()\nmodel_simple.fit(X_demo, y_demo)\ny_simple = model_simple.predict(X_test_demo)\n\naxes[0].scatter(X_demo, y_demo, c='blue', s=60, label='Training data', zorder=5)\naxes[0].plot(X_test_demo, y_simple, 'r-', linewidth=2, label='Model prediction')\naxes[0].set_title('âŒ UNDERFITTING\\n(Too simple - misses pattern)', fontsize=11)\naxes[0].set_xlabel('Feature (e.g., file size)')\naxes[0].set_ylabel('Target (e.g., threat score)')\naxes[0].legend(fontsize=8)\naxes[0].grid(True, alpha=0.3)\n\n# Model 2: Good fit (just right)\nmodel_good = make_pipeline(PolynomialFeatures(3), LinearRegression())\nmodel_good.fit(X_demo, y_demo)\ny_good = model_good.predict(X_test_demo)\n\naxes[1].scatter(X_demo, y_demo, c='blue', s=60, label='Training data', zorder=5)\naxes[1].plot(X_test_demo, y_good, 'g-', linewidth=2, label='Model prediction')\naxes[1].set_title('âœ… GOOD FIT\\n(Captures pattern, ignores noise)', fontsize=11)\naxes[1].set_xlabel('Feature (e.g., file size)')\naxes[1].legend(fontsize=8)\naxes[1].grid(True, alpha=0.3)\n\n# Model 3: Overfitting (too complex - memorizes noise)\nmodel_overfit = make_pipeline(PolynomialFeatures(12), LinearRegression())\nmodel_overfit.fit(X_demo, y_demo)\ny_overfit = model_overfit.predict(X_test_demo)\n\naxes[2].scatter(X_demo, y_demo, c='blue', s=60, label='Training data', zorder=5)\naxes[2].plot(X_test_demo, y_overfit, 'orange', linewidth=2, label='Model prediction')\naxes[2].set_title('âŒ OVERFITTING\\n(Memorizes noise, fails on new data)', fontsize=11)\naxes[2].set_xlabel('Feature (e.g., file size)')\naxes[2].legend(fontsize=8)\naxes[2].grid(True, alpha=0.3)\naxes[2].set_ylim(-4, 4)  # Limit y-axis to show the wild oscillations\n\nplt.tight_layout()\nplt.suptitle('The Goldilocks Problem: Finding the Right Model Complexity', y=1.02, fontsize=13)\nplt.show()\n\nprint(\"\\nğŸ“– What You're Seeing:\")\nprint(\"=\" * 60)\nprint(\"  â€¢ Blue dots: Training data (what the model learned from)\")\nprint(\"  â€¢ Lines: What the model predicts\")\nprint()\nprint(\"  LEFT (Underfitting): Model too simple\")\nprint(\"    â†’ Misses the underlying pattern entirely\")\nprint(\"    â†’ Bad on training data AND test data\")\nprint()\nprint(\"  MIDDLE (Good Fit): Model complexity just right\")\nprint(\"    â†’ Captures the real pattern\")\nprint(\"    â†’ Ignores random noise in training data\")\nprint(\"    â†’ Works well on NEW data!\")\nprint()\nprint(\"  RIGHT (Overfitting): Model too complex\")  \nprint(\"    â†’ Perfectly fits every training point (including noise!)\")\nprint(\"    â†’ Wild predictions between training points\")\nprint(\"    â†’ Fails badly on new data\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation Metrics\n",
    "\n",
    "For classification:\n",
    "- **Accuracy**: % correct predictions\n",
    "- **Precision**: Of predicted positives, how many are correct?\n",
    "- **Recall**: Of actual positives, how many did we find?\n",
    "- **F1 Score**: Balance of precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Example predictions\n",
    "y_true = [1, 1, 1, 0, 0, 0, 1, 0, 1, 0]  # Actual labels\n",
    "y_pred = [1, 1, 0, 0, 0, 1, 1, 0, 1, 0]  # Model predictions\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=[\"Benign\", \"Malicious\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Security Context: Why Metrics Matter\n",
    "\n",
    "**High Recall needed when:**\n",
    "- Missing a threat is costly (malware detection)\n",
    "- Better to have false alarms than miss attacks\n",
    "\n",
    "**High Precision needed when:**\n",
    "- False positives are expensive (blocking legitimate users)\n",
    "- Alert fatigue is a concern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of precision vs recall tradeoff\n",
    "thresholds = np.linspace(0.1, 0.9, 9)\n",
    "precision = [0.5, 0.55, 0.6, 0.7, 0.8, 0.85, 0.9, 0.95, 0.98]\n",
    "recall = [0.98, 0.95, 0.9, 0.85, 0.75, 0.65, 0.5, 0.35, 0.2]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(thresholds, precision, \"b-o\", label=\"Precision\")\n",
    "plt.plot(thresholds, recall, \"r-o\", label=\"Recall\")\n",
    "plt.xlabel(\"Detection Threshold\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Precision vs Recall Tradeoff\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Supervised**: Learn from labeled examples\n",
    "2. **Unsupervised**: Find patterns without labels\n",
    "3. **Features**: Input data the model uses\n",
    "4. **Train/Test Split**: Evaluate on unseen data\n",
    "5. **Metrics**: Choose based on security context\n",
    "\n",
    "## Next Steps\n",
    "- **Lab 02**: Prompt Engineering Mastery\n",
    "- **Lab 10**: Build your first classifier!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
