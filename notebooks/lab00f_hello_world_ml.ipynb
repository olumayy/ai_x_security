{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 00f: Hello World ML\n",
        "\n",
        "Your first machine learning model - a simple spam classifier in under 50 lines!\n",
        "\n",
        "## Learning Objectives\n",
        "- Understand the 4-step ML workflow: Load â†’ Train â†’ Predict â†’ Evaluate\n",
        "- Build a working classifier with scikit-learn\n",
        "- Know what accuracy, precision, and recall mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Install dependencies (Colab only)\n",
        "#@markdown Run this cell to install required packages in Colab\n",
        "\n",
        "%pip install -q numpy scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "print(\"âœ… Libraries loaded!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load Data\n",
        "\n",
        "Our dataset has messages labeled as spam (1) or not spam (0):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample spam and not-spam messages\n",
        "MESSAGES = [\n",
        "    # Spam (label = 1)\n",
        "    \"FREE MONEY! Click now to claim your prize!\",\n",
        "    \"URGENT: Your account has been compromised!\",\n",
        "    \"Congratulations! You've won $1,000,000!\",\n",
        "    \"Click here for FREE iPhone!\",\n",
        "    \"WINNER! Cash prize waiting!\",\n",
        "    \"FREE FREE FREE! Don't miss this!\",\n",
        "    \"Urgent action required!\",\n",
        "    \"You've won a FREE vacation!\",\n",
        "    \"AMAZING DEAL! Get rich quick!\",\n",
        "    \"Claim your prize money now!\",\n",
        "    # Not spam (label = 0)\n",
        "    \"Hey, want to grab lunch tomorrow?\",\n",
        "    \"Meeting moved to 3pm, see you there\",\n",
        "    \"Can you review the document?\",\n",
        "    \"Thanks for your help\",\n",
        "    \"The report is ready for review\",\n",
        "    \"Let's schedule a call for next week\",\n",
        "    \"Please find the attached invoice\",\n",
        "    \"Looking forward to the conference\",\n",
        "    \"Here's the quarterly update\",\n",
        "    \"Can we discuss the budget?\",\n",
        "]\n",
        "\n",
        "LABELS = [1]*10 + [0]*10  # First 10 spam, last 10 not spam\n",
        "SPAM_WORDS = [\"free\", \"win\", \"click\", \"urgent\", \"money\", \"prize\", \"congratulations\"]\n",
        "\n",
        "print(f\"ðŸ“Š Loaded {len(MESSAGES)} messages\")\n",
        "print(f\"   Spam: {sum(LABELS)}, Not spam: {len(LABELS) - sum(LABELS)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Understanding the ML Workflow\n",
        "\n",
        "Before we code, understand what we're building:\n",
        "\n",
        "```\n",
        "\"FREE MONEY NOW!\"     â†’  [3]  â†’  Model  â†’  1 (SPAM)\n",
        "       â†“                   â†“\n",
        "   Count spam words    Feature vector\n",
        "```\n",
        "\n",
        "**Key Insight**: ML models need numbers, not text. Our \"feature extraction\" step converts text to numbers.\n",
        "\n",
        "### The 4-Step Workflow\n",
        "\n",
        "```\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚                    ML WORKFLOW                               â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚                                                             â”‚\n",
        "â”‚   1. LOAD DATA        2. TRAIN MODEL                        â”‚\n",
        "â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                         â”‚\n",
        "â”‚   Load examples       Let algorithm                         â”‚\n",
        "â”‚   with labels         learn patterns                        â”‚\n",
        "â”‚                                                             â”‚\n",
        "â”‚         â”‚                   â”‚                               â”‚\n",
        "â”‚         â–¼                   â–¼                               â”‚\n",
        "â”‚                                                             â”‚\n",
        "â”‚   3. PREDICT          4. EVALUATE                           â”‚\n",
        "â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                          â”‚\n",
        "â”‚   Apply model         Measure how                           â”‚\n",
        "â”‚   to new data         well it works                         â”‚\n",
        "â”‚                                                             â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Feature Extraction\n",
        "\n",
        "Convert text to numbers by counting spam indicator words:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_features(message: str) -> list:\n",
        "    \"\"\"\n",
        "    Convert text to numbers by counting spam words.\n",
        "\n",
        "    Why this works:\n",
        "    - Spam emails use urgency words: \"FREE\", \"URGENT\", \"WIN\"\n",
        "    - Normal emails rarely stack these words\n",
        "    - More spam words = higher probability of spam\n",
        "    \"\"\"\n",
        "    message_lower = message.lower()\n",
        "    spam_word_count = sum(1 for word in SPAM_WORDS if word in message_lower)\n",
        "    return [spam_word_count]\n",
        "\n",
        "# Test it\n",
        "print(\"Testing feature extraction:\")\n",
        "print(f\"  'FREE MONEY! Click NOW!' â†’ {extract_features('FREE MONEY! Click NOW!')}\")\n",
        "print(f\"  'Meeting at 3pm tomorrow' â†’ {extract_features('Meeting at 3pm tomorrow')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Prepare Data\n",
        "\n",
        "Extract features from all messages and split into training/testing sets:\n",
        "\n",
        "**Why split?** If we train AND test on the same data, the model \"cheats\" by memorizing answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract features from all messages\n",
        "features = [extract_features(msg) for msg in MESSAGES]\n",
        "X = np.array(features)  # Features (inputs)\n",
        "y = np.array(LABELS)    # Labels (what we want to predict)\n",
        "\n",
        "# Split: 80% training, 20% testing\n",
        "# random_state=42 makes the split reproducible\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,      # 20% for testing\n",
        "    random_state=42     # Reproducible split\n",
        ")\n",
        "\n",
        "print(f\"ðŸ“Š Data prepared:\")\n",
        "print(f\"   Training samples: {len(X_train)}\")\n",
        "print(f\"   Test samples: {len(X_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Train the Model\n",
        "\n",
        "Use Logistic Regression - simple and effective for binary classification:\n",
        "\n",
        "| Property | Why It's Good for Beginners |\n",
        "|----------|----------------------------|\n",
        "| Simple | Only one line to train |\n",
        "| Fast | Milliseconds on small data |\n",
        "| Interpretable | Can see feature weights |\n",
        "| Works | Good baseline accuracy |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"âœ… Model trained!\")\n",
        "print(f\"   What it learned: {model.coef_[0][0]:.2f} weight for spam word count\")\n",
        "print(f\"   Interpretation: More spam words â†’ More likely spam\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Make Predictions\n",
        "\n",
        "Apply the trained model to the test data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions on test data\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "print(\"ðŸ”® Predictions made!\")\n",
        "print(f\"   Test features: {X_test.flatten()}\")\n",
        "print(f\"   Predictions:   {predictions}\")\n",
        "print(f\"   Actual labels: {y_test}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Evaluate the Model\n",
        "\n",
        "How do we know if our model is good? Use the **confusion matrix**:\n",
        "\n",
        "```\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚                    CONFUSION MATRIX                     â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚                      Predicted                          â”‚\n",
        "â”‚                  SPAM      NOT SPAM                     â”‚\n",
        "â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚\n",
        "â”‚   Actual     â”‚          â”‚          â”‚                    â”‚\n",
        "â”‚   SPAM       â”‚    TP    â”‚    FN    â”‚ â†’ Recall           â”‚\n",
        "â”‚              â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                    â”‚\n",
        "â”‚   NOT SPAM   â”‚    FP    â”‚    TN    â”‚                    â”‚\n",
        "â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚\n",
        "â”‚                    â†“                                    â”‚\n",
        "â”‚               Precision                                 â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚  Accuracy  = (TP + TN) / Total     Overall correctness  â”‚\n",
        "â”‚  Precision = TP / (TP + FP)        \"How many predicted  â”‚\n",
        "â”‚                                     spam were correct?\" â”‚\n",
        "â”‚  Recall    = TP / (TP + FN)        \"How many real spam  â”‚\n",
        "â”‚                                     did we catch?\"      â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "```\n",
        "\n",
        "### Which Metric Matters?\n",
        "\n",
        "| Use Case | Focus On | Why |\n",
        "|----------|----------|-----|\n",
        "| General | Accuracy | Overall correctness |\n",
        "| Spam filter | Precision | Don't block legitimate emails |\n",
        "| Security alert | Recall | Don't miss real threats |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "precision = precision_score(y_test, predictions)\n",
        "recall = recall_score(y_test, predictions)\n",
        "\n",
        "print(\"ðŸ“ˆ Model Evaluation:\")\n",
        "print(f\"   Accuracy:  {accuracy:.1%} (overall correctness)\")\n",
        "print(f\"   Precision: {precision:.1%} (of predicted spam, how many were actually spam)\")\n",
        "print(f\"   Recall:    {recall:.1%} (of actual spam, how many did we catch)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸŽ‰ Congratulations!\n",
        "\n",
        "You just built your first ML model! Here's what you learned:\n",
        "\n",
        "1. **ML workflow**: Load â†’ Extract Features â†’ Split â†’ Train â†’ Predict â†’ Evaluate\n",
        "2. **Features matter**: What you measure determines what the model learns\n",
        "3. **Always split data**: Test on unseen data to measure true performance\n",
        "4. **Understand metrics**: Accuracy isn't everything; consider precision and recall\n",
        "\n",
        "## ðŸš€ Bonus Challenges\n",
        "\n",
        "### Challenge 1: Add More Features\n",
        "\n",
        "```python\n",
        "def extract_features_v2(message: str) -> list:\n",
        "    message_lower = message.lower()\n",
        "    return [\n",
        "        sum(1 for word in SPAM_WORDS if word in message_lower),  # Spam word count\n",
        "        len(message),                    # Message length\n",
        "        message.count(\"!\"),              # Exclamation marks\n",
        "        sum(1 for c in message if c.isupper()) / max(len(message), 1),  # Caps ratio\n",
        "    ]\n",
        "```\n",
        "\n",
        "### Challenge 2: Try Different Models\n",
        "\n",
        "```python\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Random Forest (usually better)\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Decision Tree (more interpretable)\n",
        "model = DecisionTreeClassifier(random_state=42)\n",
        "```\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "Continue to:\n",
        "- **Lab 01**: Build a real phishing classifier with TF-IDF\n",
        "- **Lab 02**: Learn unsupervised learning (clustering)\n",
        "- **Lab 03**: Detect anomalies in network data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
