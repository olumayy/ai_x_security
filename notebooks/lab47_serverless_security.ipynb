{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Lab 47: Serverless Security Analysis\n\n## Overview\n\nAnalyze security threats unique to serverless environments including function vulnerabilities, event injection, permission misconfigurations, and cold start attacks.\n\n**Difficulty**: Intermediate  \n**Duration**: 90-120 minutes  \n**Prerequisites**: Lab 45 (Cloud Fundamentals), basic serverless knowledge\n\n## Learning Objectives\n\nBy the end of this lab, you will be able to:\n1. Analyze serverless function logs for security events\n2. Detect event injection and data poisoning attacks\n3. Investigate IAM permission misconfigurations\n4. Identify cold start timing attacks\n\n**Next:** Lab 48 (Cloud IR Automation)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "#@title Install dependencies (Colab only)\n",
    "#@markdown Run this cell to install required packages in Colab\n",
    "\n",
    "%pip install -q pandas numpy scikit-learn"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Any, Tuple\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Lambda Log Analysis\n",
    "\n",
    "Parse and analyze CloudWatch logs from Lambda functions to detect security events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def parse_lambda_logs(log_events: List[Dict]) -> pd.DataFrame:\n",
    "    \"\"\"Parse CloudWatch logs from Lambda functions.\"\"\"\n",
    "    parsed = []\n",
    "    \n",
    "    for event in log_events:\n",
    "        message = event.get('message', '')\n",
    "        timestamp = datetime.fromtimestamp(\n",
    "            event.get('timestamp', 0) / 1000\n",
    "        )\n",
    "        \n",
    "        log_entry = {\n",
    "            'timestamp': timestamp,\n",
    "            'raw_message': message,\n",
    "            'log_type': classify_log_type(message)\n",
    "        }\n",
    "        \n",
    "        # Extract request ID\n",
    "        request_id_match = re.search(\n",
    "            r'RequestId:\\s*([a-f0-9-]+)',\n",
    "            message\n",
    "        )\n",
    "        if request_id_match:\n",
    "            log_entry['request_id'] = request_id_match.group(1)\n",
    "        \n",
    "        # Parse START/END/REPORT lines\n",
    "        if message.startswith('START'):\n",
    "            log_entry['event'] = 'invocation_start'\n",
    "        elif message.startswith('END'):\n",
    "            log_entry['event'] = 'invocation_end'\n",
    "        elif message.startswith('REPORT'):\n",
    "            log_entry['event'] = 'invocation_report'\n",
    "            log_entry.update(parse_report_line(message))\n",
    "        else:\n",
    "            log_entry['event'] = 'application_log'\n",
    "        \n",
    "        parsed.append(log_entry)\n",
    "    \n",
    "    return pd.DataFrame(parsed)\n",
    "\n",
    "\n",
    "def parse_report_line(message: str) -> Dict:\n",
    "    \"\"\"Extract metrics from REPORT line.\"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    patterns = {\n",
    "        'duration': r'Duration:\\s*([\\d.]+)\\s*ms',\n",
    "        'billed_duration': r'Billed Duration:\\s*(\\d+)\\s*ms',\n",
    "        'memory_size': r'Memory Size:\\s*(\\d+)\\s*MB',\n",
    "        'memory_used': r'Max Memory Used:\\s*(\\d+)\\s*MB',\n",
    "        'init_duration': r'Init Duration:\\s*([\\d.]+)\\s*ms'\n",
    "    }\n",
    "    \n",
    "    for key, pattern in patterns.items():\n",
    "        match = re.search(pattern, message)\n",
    "        if match:\n",
    "            metrics[key] = float(match.group(1))\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "def classify_log_type(message: str) -> str:\n",
    "    \"\"\"Classify log message type.\"\"\"\n",
    "    if message.startswith(('START', 'END', 'REPORT')):\n",
    "        return 'platform'\n",
    "    elif 'ERROR' in message or 'Exception' in message:\n",
    "        return 'error'\n",
    "    elif re.match(r'\\d{4}-\\d{2}-\\d{2}', message):\n",
    "        return 'application'\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "print(\"Lambda log parser ready!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Demo: Parse Lambda logs\n",
    "print(\"LAMBDA LOG PARSING DEMO\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Simulated CloudWatch log events\n",
    "sample_log_events = [\n",
    "    {'timestamp': 1705312800000, 'message': 'START RequestId: abc-123 Version: $LATEST'},\n",
    "    {'timestamp': 1705312800100, 'message': '2024-01-15T10:00:00.100Z abc-123 INFO Processing request'},\n",
    "    {'timestamp': 1705312800200, 'message': '2024-01-15T10:00:00.200Z abc-123 INFO Query: SELECT * FROM users'},\n",
    "    {'timestamp': 1705312800500, 'message': 'END RequestId: abc-123'},\n",
    "    {'timestamp': 1705312800600, 'message': 'REPORT RequestId: abc-123 Duration: 450.00 ms Billed Duration: 500 ms Memory Size: 128 MB Max Memory Used: 64 MB Init Duration: 150.00 ms'},\n",
    "    {'timestamp': 1705312801000, 'message': 'START RequestId: def-456 Version: $LATEST'},\n",
    "    {'timestamp': 1705312801100, 'message': '2024-01-15T10:00:01.100Z def-456 ERROR Connection timeout'},\n",
    "    {'timestamp': 1705312801200, 'message': 'END RequestId: def-456'},\n",
    "    {'timestamp': 1705312801300, 'message': 'REPORT RequestId: def-456 Duration: 30000.00 ms Billed Duration: 30000 ms Memory Size: 128 MB Max Memory Used: 100 MB'},\n",
    "]\n",
    "\n",
    "# Parse logs\n",
    "logs_df = parse_lambda_logs(sample_log_events)\n",
    "\n",
    "print(\"\\nParsed Log Events:\")\n",
    "print(logs_df[['timestamp', 'event', 'log_type']].to_string())\n",
    "\n",
    "# Extract metrics from REPORT lines\n",
    "reports = logs_df[logs_df['event'] == 'invocation_report']\n",
    "print(\"\\n\" + \"-\" * 50)\n",
    "print(\"Invocation Metrics:\")\n",
    "for _, report in reports.iterrows():\n",
    "    print(f\"\\n  Request: {report.get('request_id', 'N/A')}\")\n",
    "    print(f\"    Duration: {report.get('duration', 'N/A')} ms\")\n",
    "    print(f\"    Memory Used: {report.get('memory_used', 'N/A')} MB\")\n",
    "    if pd.notna(report.get('init_duration')):\n",
    "        print(f\"    Cold Start: Yes ({report['init_duration']} ms)\")\n",
    "    else:\n",
    "        print(f\"    Cold Start: No\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Invocation Anomaly Detection\n",
    "\n",
    "Detect anomalous function invocations that may indicate attacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def detect_invocation_anomalies(logs_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Detect anomalous function invocations.\"\"\"\n",
    "    # Filter to report lines only\n",
    "    reports = logs_df[logs_df['event'] == 'invocation_report'].copy()\n",
    "    \n",
    "    if len(reports) < 10:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Aggregate metrics per time window\n",
    "    reports['hour'] = reports['timestamp'].dt.floor('H')\n",
    "    \n",
    "    hourly_stats = reports.groupby('hour').agg({\n",
    "        'duration': ['mean', 'max', 'std'],\n",
    "        'memory_used': ['mean', 'max'],\n",
    "        'request_id': 'count'\n",
    "    }).reset_index()\n",
    "    \n",
    "    hourly_stats.columns = [\n",
    "        'hour', 'duration_mean', 'duration_max', 'duration_std',\n",
    "        'memory_mean', 'memory_max', 'invocation_count'\n",
    "    ]\n",
    "    hourly_stats = hourly_stats.fillna(0)\n",
    "    \n",
    "    # Prepare features for anomaly detection\n",
    "    features = hourly_stats[[\n",
    "        'duration_mean', 'duration_max',\n",
    "        'memory_mean', 'invocation_count'\n",
    "    ]]\n",
    "    \n",
    "    # Detect anomalies with Isolation Forest\n",
    "    iso = IsolationForest(contamination=0.1, random_state=42)\n",
    "    hourly_stats['anomaly'] = iso.fit_predict(features)\n",
    "    \n",
    "    # Anomalies have score -1\n",
    "    anomalies = hourly_stats[hourly_stats['anomaly'] == -1]\n",
    "    \n",
    "    return anomalies\n",
    "\n",
    "\n",
    "def detect_error_spikes(logs_df: pd.DataFrame, threshold: float = 3.0) -> pd.DataFrame:\n",
    "    \"\"\"Detect sudden increases in error rates.\"\"\"\n",
    "    errors = logs_df[logs_df['log_type'] == 'error'].copy()\n",
    "    \n",
    "    if len(errors) == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    errors['hour'] = errors['timestamp'].dt.floor('H')\n",
    "    error_counts = errors.groupby('hour').size().reset_index(name='error_count')\n",
    "    \n",
    "    # Calculate rolling average\n",
    "    error_counts['rolling_avg'] = error_counts['error_count'].rolling(\n",
    "        window=24, min_periods=1\n",
    "    ).mean()\n",
    "    \n",
    "    # Find spikes\n",
    "    error_counts['is_spike'] = (\n",
    "        error_counts['error_count'] >\n",
    "        error_counts['rolling_avg'] * threshold\n",
    "    )\n",
    "    \n",
    "    return error_counts[error_counts['is_spike']]\n",
    "\n",
    "\n",
    "def analyze_cold_starts(logs_df: pd.DataFrame) -> Dict:\n",
    "    \"\"\"Analyze cold start patterns for security implications.\"\"\"\n",
    "    reports = logs_df[logs_df['event'] == 'invocation_report'].copy()\n",
    "    \n",
    "    if len(reports) == 0:\n",
    "        return {'status': 'no_data'}\n",
    "    \n",
    "    # Identify cold starts (have init_duration)\n",
    "    reports['is_cold_start'] = reports['init_duration'].notna()\n",
    "    \n",
    "    stats = {\n",
    "        'total_invocations': len(reports),\n",
    "        'cold_starts': reports['is_cold_start'].sum(),\n",
    "        'cold_start_rate': reports['is_cold_start'].mean(),\n",
    "        'avg_cold_start_duration': reports[\n",
    "            reports['is_cold_start']\n",
    "        ]['init_duration'].mean() if reports['is_cold_start'].any() else 0,\n",
    "        'avg_warm_duration': reports[\n",
    "            ~reports['is_cold_start']\n",
    "        ]['duration'].mean() if (~reports['is_cold_start']).any() else 0\n",
    "    }\n",
    "    \n",
    "    return stats\n",
    "\n",
    "print(\"Invocation anomaly detector ready!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Demo: Cold start analysis\n",
    "print(\"COLD START ANALYSIS DEMO\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create more extensive log data\n",
    "base_time = datetime(2024, 1, 15, 10, 0, 0)\n",
    "extended_logs = []\n",
    "\n",
    "for i in range(100):\n",
    "    ts = base_time + timedelta(minutes=i)\n",
    "    is_cold = i % 20 == 0  # Cold start every 20th invocation\n",
    "    \n",
    "    report_msg = f'REPORT RequestId: req-{i:03d} Duration: {np.random.uniform(50, 500):.2f} ms Billed Duration: 500 ms Memory Size: 128 MB Max Memory Used: {np.random.randint(40, 100)} MB'\n",
    "    if is_cold:\n",
    "        report_msg += f' Init Duration: {np.random.uniform(100, 300):.2f} ms'\n",
    "    \n",
    "    extended_logs.append({\n",
    "        'timestamp': int(ts.timestamp() * 1000),\n",
    "        'message': report_msg\n",
    "    })\n",
    "\n",
    "# Parse logs\n",
    "extended_df = parse_lambda_logs(extended_logs)\n",
    "\n",
    "# Analyze cold starts\n",
    "cold_start_stats = analyze_cold_starts(extended_df)\n",
    "\n",
    "print(\"\\nCold Start Statistics:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"  Total Invocations: {cold_start_stats['total_invocations']}\")\n",
    "print(f\"  Cold Starts: {cold_start_stats['cold_starts']}\")\n",
    "print(f\"  Cold Start Rate: {cold_start_stats['cold_start_rate']:.1%}\")\n",
    "print(f\"  Avg Cold Start Duration: {cold_start_stats['avg_cold_start_duration']:.2f} ms\")\n",
    "print(f\"  Avg Warm Duration: {cold_start_stats['avg_warm_duration']:.2f} ms\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Event Injection Detection\n",
    "\n",
    "Detect injection attacks in event payloads from API Gateway, S3, and other event sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class EventInjectionDetector:\n",
    "    \"\"\"Detect injection attacks in serverless event payloads.\"\"\"\n",
    "    \n",
    "    INJECTION_PATTERNS = {\n",
    "        'sql_injection': [\n",
    "            r\"(?i)(\\b(SELECT|INSERT|UPDATE|DELETE|DROP|UNION|ALTER)\\b.*\\b(FROM|INTO|SET|TABLE)\\b)\",\n",
    "            r\"(?i)('\\s*(OR|AND)\\s*'?\\d+'\\s*=\\s*'?\\d+)\",\n",
    "            r\"(?i)(--\\s*$|;\\s*--)\",\n",
    "        ],\n",
    "        'command_injection': [\n",
    "            r\"[;&|`$]\",\n",
    "            r\"(?i)\\$\\(.*\\)\",\n",
    "            r\"(?i)\\b(cat|ls|pwd|whoami|id|wget|curl)\\b\\s\",\n",
    "        ],\n",
    "        'path_traversal': [\n",
    "            r\"\\.\\./\",\n",
    "            r\"\\.\\.\\\\\",\n",
    "            r\"%2e%2e[/\\\\]\",\n",
    "        ],\n",
    "        'xss': [\n",
    "            r\"<script[^>]*>\",\n",
    "            r\"javascript:\",\n",
    "            r\"on\\w+\\s*=\",\n",
    "        ],\n",
    "        'ssrf': [\n",
    "            r\"(?i)(localhost|127\\.0\\.0\\.1|0\\.0\\.0\\.0)\",\n",
    "            r\"(?i)169\\.254\\.169\\.254\",  # AWS metadata\n",
    "            r\"(?i)metadata\\.google\",     # GCP metadata\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.findings = []\n",
    "    \n",
    "    def analyze_event(self, event: Dict, request_id: str = None) -> List[Dict]:\n",
    "        \"\"\"Analyze an event payload for injection patterns.\"\"\"\n",
    "        findings = []\n",
    "        \n",
    "        # Convert event to string for pattern matching\n",
    "        payload = json.dumps(event)\n",
    "        \n",
    "        for attack_type, patterns in self.INJECTION_PATTERNS.items():\n",
    "            for pattern in patterns:\n",
    "                if re.search(pattern, payload):\n",
    "                    finding = {\n",
    "                        'timestamp': datetime.now(),\n",
    "                        'request_id': request_id,\n",
    "                        'attack_type': attack_type,\n",
    "                        'pattern': pattern,\n",
    "                        'payload_preview': payload[:200]\n",
    "                    }\n",
    "                    findings.append(finding)\n",
    "                    self.findings.append(finding)\n",
    "                    break\n",
    "        \n",
    "        return findings\n",
    "    \n",
    "    def get_summary(self) -> Dict:\n",
    "        \"\"\"Get summary of detected injections.\"\"\"\n",
    "        if not self.findings:\n",
    "            return {'total': 0}\n",
    "        \n",
    "        by_type = {}\n",
    "        for finding in self.findings:\n",
    "            attack_type = finding['attack_type']\n",
    "            by_type[attack_type] = by_type.get(attack_type, 0) + 1\n",
    "        \n",
    "        return {\n",
    "            'total': len(self.findings),\n",
    "            'by_type': by_type\n",
    "        }\n",
    "\n",
    "print(\"Event injection detector ready!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Demo: Event injection detection\n",
    "print(\"EVENT INJECTION DETECTION DEMO\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "detector = EventInjectionDetector()\n",
    "\n",
    "# Sample API Gateway events (mix of normal and malicious)\n",
    "sample_events = [\n",
    "    # Normal request\n",
    "    {\n",
    "        'httpMethod': 'GET',\n",
    "        'path': '/users/123',\n",
    "        'queryStringParameters': {'page': '1', 'limit': '10'}\n",
    "    },\n",
    "    # SQL injection in query parameter\n",
    "    {\n",
    "        'httpMethod': 'GET',\n",
    "        'path': '/users',\n",
    "        'queryStringParameters': {'id': \"1' OR '1'='1\"}\n",
    "    },\n",
    "    # Command injection in body\n",
    "    {\n",
    "        'httpMethod': 'POST',\n",
    "        'path': '/process',\n",
    "        'body': '{\"filename\": \"test.txt; cat /etc/passwd\"}'\n",
    "    },\n",
    "    # Path traversal\n",
    "    {\n",
    "        'httpMethod': 'GET',\n",
    "        'path': '/files/../../../etc/passwd',\n",
    "        'queryStringParameters': None\n",
    "    },\n",
    "    # SSRF attempt\n",
    "    {\n",
    "        'httpMethod': 'POST',\n",
    "        'path': '/fetch',\n",
    "        'body': '{\"url\": \"http://169.254.169.254/latest/meta-data/iam/security-credentials/\"}'\n",
    "    },\n",
    "    # Normal request\n",
    "    {\n",
    "        'httpMethod': 'POST',\n",
    "        'path': '/users',\n",
    "        'body': '{\"name\": \"John Doe\", \"email\": \"john@example.com\"}'\n",
    "    },\n",
    "]\n",
    "\n",
    "print(\"\\nAnalyzing events...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for i, event in enumerate(sample_events):\n",
    "    findings = detector.analyze_event(event, f'req-{i:03d}')\n",
    "    \n",
    "    print(f\"\\nEvent {i+1}: {event.get('httpMethod')} {event.get('path')}\")\n",
    "    if findings:\n",
    "        for finding in findings:\n",
    "            print(f\"  ALERT: {finding['attack_type']} detected!\")\n",
    "    else:\n",
    "        print(f\"  Status: Clean\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"DETECTION SUMMARY\")\n",
    "summary = detector.get_summary()\n",
    "print(f\"Total Attacks Detected: {summary['total']}\")\n",
    "print(f\"By Type: {summary.get('by_type', {})}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Permission Analysis\n",
    "\n",
    "Analyze Lambda function IAM roles for over-permissive configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class FunctionPermissionAnalyzer:\n",
    "    \"\"\"Analyze Lambda function IAM role permissions.\"\"\"\n",
    "    \n",
    "    SENSITIVE_PERMISSIONS = {\n",
    "        'critical': [\n",
    "            'iam:*',\n",
    "            '*:*',\n",
    "            'sts:AssumeRole',\n",
    "            'organizations:*',\n",
    "            'kms:Decrypt',\n",
    "        ],\n",
    "        'high': [\n",
    "            's3:*',\n",
    "            'dynamodb:*',\n",
    "            'secretsmanager:GetSecretValue',\n",
    "            'ssm:GetParameter*',\n",
    "            'lambda:InvokeFunction',\n",
    "            'ec2:*',\n",
    "        ],\n",
    "        'medium': [\n",
    "            's3:GetObject',\n",
    "            's3:PutObject',\n",
    "            'dynamodb:GetItem',\n",
    "            'dynamodb:PutItem',\n",
    "            'logs:*',\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.findings = []\n",
    "    \n",
    "    def analyze_function(self, function_config: Dict) -> Dict:\n",
    "        \"\"\"Analyze a function's permissions.\"\"\"\n",
    "        function_name = function_config.get('function_name', 'unknown')\n",
    "        policies = function_config.get('policies', [])\n",
    "        \n",
    "        result = {\n",
    "            'function_name': function_name,\n",
    "            'critical_permissions': [],\n",
    "            'high_permissions': [],\n",
    "            'medium_permissions': [],\n",
    "            'is_overprivileged': False,\n",
    "            'risk_score': 0\n",
    "        }\n",
    "        \n",
    "        for policy in policies:\n",
    "            for statement in policy.get('Statement', []):\n",
    "                actions = statement.get('Action', [])\n",
    "                if isinstance(actions, str):\n",
    "                    actions = [actions]\n",
    "                \n",
    "                for action in actions:\n",
    "                    for severity, patterns in self.SENSITIVE_PERMISSIONS.items():\n",
    "                        if self._matches_pattern(action, patterns):\n",
    "                            result[f'{severity}_permissions'].append(action)\n",
    "        \n",
    "        # Calculate risk score\n",
    "        result['risk_score'] = (\n",
    "            len(result['critical_permissions']) * 30 +\n",
    "            len(result['high_permissions']) * 15 +\n",
    "            len(result['medium_permissions']) * 5\n",
    "        )\n",
    "        \n",
    "        # Determine if overprivileged\n",
    "        result['is_overprivileged'] = (\n",
    "            len(result['critical_permissions']) > 0 or\n",
    "            len(result['high_permissions']) > 5\n",
    "        )\n",
    "        \n",
    "        self.findings.append(result)\n",
    "        return result\n",
    "    \n",
    "    def _matches_pattern(self, action: str, patterns: List[str]) -> bool:\n",
    "        \"\"\"Check if action matches any pattern.\"\"\"\n",
    "        for pattern in patterns:\n",
    "            # Convert wildcard pattern to regex\n",
    "            regex_pattern = pattern.replace('*', '.*')\n",
    "            if re.match(regex_pattern, action, re.IGNORECASE):\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def get_summary(self) -> Dict:\n",
    "        \"\"\"Get summary of permission analysis.\"\"\"\n",
    "        if not self.findings:\n",
    "            return {'functions_analyzed': 0}\n",
    "        \n",
    "        return {\n",
    "            'functions_analyzed': len(self.findings),\n",
    "            'overprivileged': sum(1 for f in self.findings if f['is_overprivileged']),\n",
    "            'avg_risk_score': np.mean([f['risk_score'] for f in self.findings]),\n",
    "            'max_risk_score': max(f['risk_score'] for f in self.findings)\n",
    "        }\n",
    "\n",
    "print(\"Permission analyzer ready!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Demo: Permission analysis\n",
    "print(\"FUNCTION PERMISSION ANALYSIS DEMO\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "analyzer = FunctionPermissionAnalyzer()\n",
    "\n",
    "# Sample function configurations\n",
    "sample_functions = [\n",
    "    {\n",
    "        'function_name': 'api-handler',\n",
    "        'policies': [\n",
    "            {\n",
    "                'Statement': [\n",
    "                    {'Action': ['logs:CreateLogGroup', 'logs:PutLogEvents']},\n",
    "                    {'Action': 'dynamodb:GetItem'}\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'function_name': 'data-processor',\n",
    "        'policies': [\n",
    "            {\n",
    "                'Statement': [\n",
    "                    {'Action': 's3:*'},  # Overly permissive!\n",
    "                    {'Action': 'dynamodb:*'},\n",
    "                    {'Action': 'secretsmanager:GetSecretValue'}\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'function_name': 'admin-function',\n",
    "        'policies': [\n",
    "            {\n",
    "                'Statement': [\n",
    "                    {'Action': '*:*'},  # DANGER: Full access!\n",
    "                    {'Action': 'iam:*'}\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"\\nAnalyzing function permissions...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for func in sample_functions:\n",
    "    result = analyzer.analyze_function(func)\n",
    "    \n",
    "    print(f\"\\nFunction: {result['function_name']}\")\n",
    "    print(f\"  Risk Score: {result['risk_score']}\")\n",
    "    print(f\"  Overprivileged: {result['is_overprivileged']}\")\n",
    "    \n",
    "    if result['critical_permissions']:\n",
    "        print(f\"  CRITICAL: {result['critical_permissions']}\")\n",
    "    if result['high_permissions']:\n",
    "        print(f\"  HIGH: {result['high_permissions']}\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"ANALYSIS SUMMARY\")\n",
    "summary = analyzer.get_summary()\n",
    "print(f\"Functions Analyzed: {summary['functions_analyzed']}\")\n",
    "print(f\"Overprivileged Functions: {summary['overprivileged']}\")\n",
    "print(f\"Average Risk Score: {summary['avg_risk_score']:.1f}\")\n",
    "print(f\"Max Risk Score: {summary['max_risk_score']}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: API Gateway Log Analysis\n",
    "\n",
    "Analyze API Gateway access logs for security events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def analyze_api_gateway_logs(logs_df: pd.DataFrame) -> Dict:\n",
    "    \"\"\"Analyze API Gateway logs for security events.\"\"\"\n",
    "    security_events = []\n",
    "    \n",
    "    for _, log in logs_df.iterrows():\n",
    "        indicators = []\n",
    "        \n",
    "        # Check for error status codes\n",
    "        status = log.get('status', 0)\n",
    "        if status >= 400:\n",
    "            indicators.append(f'error_status_{status}')\n",
    "        \n",
    "        # Check for unusual HTTP methods\n",
    "        method = log.get('http_method', '')\n",
    "        if method not in ['GET', 'POST', 'PUT', 'DELETE', 'PATCH']:\n",
    "            indicators.append(f'unusual_method_{method}')\n",
    "        \n",
    "        # Check for suspicious paths\n",
    "        path = log.get('path', '')\n",
    "        suspicious_paths = ['/admin', '/.env', '/config', '/debug', '/actuator', '/.git']\n",
    "        if any(sp in path for sp in suspicious_paths):\n",
    "            indicators.append('suspicious_path')\n",
    "        \n",
    "        if indicators:\n",
    "            security_events.append({\n",
    "                'timestamp': log.get('timestamp'),\n",
    "                'source_ip': log.get('source_ip'),\n",
    "                'path': path,\n",
    "                'status': status,\n",
    "                'indicators': indicators\n",
    "            })\n",
    "    \n",
    "    return {'security_events': security_events, 'total': len(security_events)}\n",
    "\n",
    "\n",
    "def detect_enumeration_attempts(\n",
    "    logs_df: pd.DataFrame,\n",
    "    window_minutes: int = 5,\n",
    "    threshold: int = 20\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Detect path/parameter enumeration attempts.\"\"\"\n",
    "    logs_df = logs_df.copy()\n",
    "    logs_df['window'] = logs_df['timestamp'].dt.floor(f'{window_minutes}T')\n",
    "    \n",
    "    # Group by source IP and time window\n",
    "    grouped = logs_df.groupby(['source_ip', 'window']).agg({\n",
    "        'path': 'nunique',\n",
    "        'request_id': 'count',\n",
    "        'status': lambda x: (x == 404).sum()\n",
    "    }).reset_index()\n",
    "    \n",
    "    grouped.columns = ['source_ip', 'window', 'unique_paths',\n",
    "                       'request_count', 'not_found_count']\n",
    "    \n",
    "    # Detect enumeration: many unique paths or many 404s\n",
    "    enumeration = grouped[\n",
    "        (grouped['unique_paths'] > threshold) |\n",
    "        (grouped['not_found_count'] > threshold)\n",
    "    ]\n",
    "    \n",
    "    return enumeration\n",
    "\n",
    "print(\"API Gateway log analyzer ready!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Demo: API Gateway log analysis\n",
    "print(\"API GATEWAY LOG ANALYSIS DEMO\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create sample API Gateway logs\n",
    "base_time = datetime(2024, 1, 15, 10, 0, 0)\n",
    "\n",
    "api_logs = pd.DataFrame([\n",
    "    {'timestamp': base_time, 'source_ip': '10.0.0.1', 'http_method': 'GET', 'path': '/api/users', 'status': 200, 'request_id': 'r1'},\n",
    "    {'timestamp': base_time + timedelta(seconds=1), 'source_ip': '10.0.0.1', 'http_method': 'POST', 'path': '/api/users', 'status': 201, 'request_id': 'r2'},\n",
    "    {'timestamp': base_time + timedelta(seconds=2), 'source_ip': '192.168.1.100', 'http_method': 'GET', 'path': '/.env', 'status': 404, 'request_id': 'r3'},\n",
    "    {'timestamp': base_time + timedelta(seconds=3), 'source_ip': '192.168.1.100', 'http_method': 'GET', 'path': '/admin/config', 'status': 403, 'request_id': 'r4'},\n",
    "    {'timestamp': base_time + timedelta(seconds=4), 'source_ip': '192.168.1.100', 'http_method': 'OPTIONS', 'path': '/.git/config', 'status': 404, 'request_id': 'r5'},\n",
    "    {'timestamp': base_time + timedelta(seconds=5), 'source_ip': '10.0.0.2', 'http_method': 'GET', 'path': '/api/products', 'status': 200, 'request_id': 'r6'},\n",
    "    {'timestamp': base_time + timedelta(seconds=6), 'source_ip': '192.168.1.100', 'http_method': 'GET', 'path': '/debug/vars', 'status': 404, 'request_id': 'r7'},\n",
    "])\n",
    "\n",
    "# Analyze logs\n",
    "analysis = analyze_api_gateway_logs(api_logs)\n",
    "\n",
    "print(\"\\nSecurity Events Detected:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Total: {analysis['total']}\")\n",
    "\n",
    "for event in analysis['security_events']:\n",
    "    print(f\"\\n  IP: {event['source_ip']}\")\n",
    "    print(f\"  Path: {event['path']}\")\n",
    "    print(f\"  Status: {event['status']}\")\n",
    "    print(f\"  Indicators: {event['indicators']}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Log Analysis** - Parse Lambda logs to extract invocation metrics and detect anomalies\n",
    "2. **Cold Start Monitoring** - Track cold start patterns that may indicate probing\n",
    "3. **Event Injection Detection** - Scan event payloads for SQL injection, XSS, SSRF\n",
    "4. **Permission Analysis** - Identify overprivileged function roles\n",
    "5. **API Gateway Security** - Monitor for enumeration and suspicious access patterns\n",
    "\n",
    "## Serverless Security Checklist\n",
    "\n",
    "| Area | Check |\n",
    "|------|-------|\n",
    "| Permissions | Least privilege IAM roles |\n",
    "| Input Validation | Sanitize all event inputs |\n",
    "| Secrets | Use Secrets Manager, not env vars |\n",
    "| Dependencies | Scan for vulnerable packages |\n",
    "| Logging | Enable detailed logging |\n",
    "| Monitoring | Set up invocation anomaly alerts |\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- **Lab 48**: Cloud IR Automation - Automated incident response\n",
    "- **Lab 49**: LLM Red Teaming - Advanced security testing\n",
    "- **Lab 21**: Threat Intelligence - Enrich findings with TI"
   ]
  }
 ]
}
